{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install pandas\n",
    "# !python3 -m pip install matplotlib\n",
    "# !python3 -m pip install numpy\n",
    "# !python3 -m pip install sklearn\n",
    "# !python3 -m pip install scipy\n",
    "# !python3 -m pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/fclesio/learning-space/master/Datasets/02%20-%20Classification/default_credit_card.csv')\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train.drop([\"DEFAULT\"], axis=1)\n",
    "test_x = test.drop([\"DEFAULT\"], axis=1)\n",
    "train_y = train[[\"DEFAULT\"]]\n",
    "test_y = test[[\"DEFAULT\"]]\n",
    "\n",
    "# Convert Pandas datasets to numpy arrays \n",
    "train_x = train_x.as_matrix()\n",
    "test_x = test_x.as_matrix()\n",
    "train_y = train_y.as_matrix()\n",
    "test_y = test_y.as_matrix()\n",
    "\n",
    "# Standardize the data attributes\n",
    "train_x = preprocessing.scale(train_x)\n",
    "test_x = preprocessing.scale(test_x)\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model (n_estimators=500.000000, min_samples_split=50.000000, max_depth=10.000000):\n",
      "Accuracy: 82.67\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=50.000000, max_depth=20.000000):\n",
      "Accuracy: 82.63\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=50.000000, max_depth=50.000000):\n",
      "Accuracy: 82.6\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=100.000000, max_depth=10.000000):\n",
      "Accuracy: 82.81\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=100.000000, max_depth=20.000000):\n",
      "Accuracy: 82.76\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=100.000000, max_depth=50.000000):\n",
      "Accuracy: 82.72\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=500.000000, max_depth=10.000000):\n",
      "Accuracy: 82.73\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=500.000000, max_depth=20.000000):\n",
      "Accuracy: 82.67\n",
      "Random Forest model (n_estimators=500.000000, min_samples_split=500.000000, max_depth=50.000000):\n",
      "Accuracy: 82.75\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=50.000000, max_depth=10.000000):\n",
      "Accuracy: 82.83\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=50.000000, max_depth=20.000000):\n",
      "Accuracy: 82.69\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=50.000000, max_depth=50.000000):\n",
      "Accuracy: 82.69\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=100.000000, max_depth=10.000000):\n",
      "Accuracy: 82.75\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=100.000000, max_depth=20.000000):\n",
      "Accuracy: 82.72\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=100.000000, max_depth=50.000000):\n",
      "Accuracy: 82.77\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=500.000000, max_depth=10.000000):\n",
      "Accuracy: 82.77\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=500.000000, max_depth=20.000000):\n",
      "Accuracy: 82.75\n",
      "Random Forest model (n_estimators=1000.000000, min_samples_split=500.000000, max_depth=50.000000):\n",
      "Accuracy: 82.69\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=50.000000, max_depth=10.000000):\n",
      "Accuracy: 82.71\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=50.000000, max_depth=20.000000):\n",
      "Accuracy: 82.73\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=50.000000, max_depth=50.000000):\n",
      "Accuracy: 82.71\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=100.000000, max_depth=10.000000):\n",
      "Accuracy: 82.77\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=100.000000, max_depth=20.000000):\n",
      "Accuracy: 82.75\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=100.000000, max_depth=50.000000):\n",
      "Accuracy: 82.79\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=500.000000, max_depth=10.000000):\n",
      "Accuracy: 82.79\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=500.000000, max_depth=20.000000):\n",
      "Accuracy: 82.76\n",
      "Random Forest model (n_estimators=3000.000000, min_samples_split=500.000000, max_depth=50.000000):\n",
      "Accuracy: 82.76\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "n_estimators = [500, 1000, 3000]\n",
    "min_samples_splits = [50, 100, 500]\n",
    "max_depths = [10, 20, 50]\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    for min_samples_split in min_samples_splits:    \n",
    "        for depth in max_depths:\n",
    "            with mlflow.start_run():\n",
    "                \n",
    "                lr = RandomForestClassifier(n_estimators=n_estimator, \n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            max_depth=depth)\n",
    "            \n",
    "                lr.fit(train_x, train_y)\n",
    "                accuracy = lr.score(test_x, test_y)\n",
    "\n",
    "                predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "\n",
    "                print(\"Random Forest model (n_estimators=%f, min_samples_split=%f, max_depth=%f):\" % (n_estimator,min_samples_split,depth))\n",
    "                print(\"Accuracy: %s\" % round((accuracy * 100),2))\n",
    "\n",
    "                # Logging in mlflow to appears in UI\n",
    "                mlflow.log_param(\"n_estimators\", n_estimator)\n",
    "                mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "                mlflow.log_param(\"max_depth\", depth)\n",
    "                \n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.sklearn.log_model(lr, \"model_random_forests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting model (n_estimators=1000.000000, min_samples_leaf=20.000000, max_depth=20.000000):\n",
      "Accuracy: 82.0\n",
      "Gradient Boosting model (n_estimators=1000.000000, min_samples_leaf=20.000000, max_depth=30.000000):\n",
      "Accuracy: 81.88\n",
      "Gradient Boosting model (n_estimators=1000.000000, min_samples_leaf=50.000000, max_depth=20.000000):\n",
      "Accuracy: 81.09\n",
      "Gradient Boosting model (n_estimators=1000.000000, min_samples_leaf=50.000000, max_depth=30.000000):\n",
      "Accuracy: 81.05\n",
      "Gradient Boosting model (n_estimators=3000.000000, min_samples_leaf=20.000000, max_depth=20.000000):\n",
      "Accuracy: 81.96\n",
      "Gradient Boosting model (n_estimators=3000.000000, min_samples_leaf=20.000000, max_depth=30.000000):\n",
      "Accuracy: 81.96\n",
      "Gradient Boosting model (n_estimators=3000.000000, min_samples_leaf=50.000000, max_depth=20.000000):\n",
      "Accuracy: 81.0\n",
      "Gradient Boosting model (n_estimators=3000.000000, min_samples_leaf=50.000000, max_depth=30.000000):\n",
      "Accuracy: 81.01\n"
     ]
    }
   ],
   "source": [
    "# ExtraTreesClassifier\n",
    "n_estimators = [1000, 3000]\n",
    "max_depths = [20, 30]\n",
    "min_samples_leafs = [20, 50]\n",
    "\n",
    "for n_estimator in n_estimators:\n",
    "    for min_samples_leaf in min_samples_leafs:    \n",
    "        for depth in max_depths:\n",
    "            with mlflow.start_run():\n",
    "                \n",
    "                lr = ExtraTreesClassifier(n_estimators=n_estimator, \n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          max_depth=depth)\n",
    "            \n",
    "                lr.fit(train_x, train_y)\n",
    "                accuracy = lr.score(test_x, test_y)\n",
    "\n",
    "                predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "                print(\"Gradient Boosting model (n_estimators=%f, min_samples_leaf=%f, max_depth=%f):\" % (n_estimator, min_samples_leaf, depth))\n",
    "                print(\"Accuracy: %s\" % round((accuracy * 100),2))\n",
    "\n",
    "                # Logging in mlflow to appears in UI\n",
    "                mlflow.log_param(\"n_estimators\", n_estimator)\n",
    "                mlflow.log_param(\"min_samples_leaf\", min_samples_leaf)\n",
    "                mlflow.log_param(\"max_depth\", depth)\n",
    "                \n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.sklearn.log_model(lr, \"model_extratrees_classifier\")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.73\n",
      "Accuracy: 58.73\n",
      "Accuracy: 58.72\n",
      "Accuracy: 58.73\n",
      "Accuracy: 58.69\n",
      "Accuracy: 58.71\n",
      "Accuracy: 58.71\n",
      "Accuracy: 58.69\n",
      "Accuracy: 58.57\n",
      "Accuracy: 58.59\n",
      "Accuracy: 58.59\n",
      "Accuracy: 58.57\n",
      "Accuracy: 58.33\n",
      "Accuracy: 58.33\n",
      "Accuracy: 58.33\n",
      "Accuracy: 58.33\n",
      "Accuracy: 58.29\n",
      "Accuracy: 58.31\n",
      "Accuracy: 58.31\n",
      "Accuracy: 58.29\n",
      "Accuracy: 58.23\n",
      "Accuracy: 58.23\n",
      "Accuracy: 58.23\n",
      "Accuracy: 58.23\n",
      "Accuracy: 58.2\n",
      "Accuracy: 58.2\n",
      "Accuracy: 58.2\n",
      "Accuracy: 58.2\n",
      "Accuracy: 57.92\n",
      "Accuracy: 57.92\n",
      "Accuracy: 57.92\n",
      "Accuracy: 57.92\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.69\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.71\n",
      "Accuracy: 81.65\n",
      "Accuracy: 81.65\n",
      "Accuracy: 81.65\n",
      "Accuracy: 81.65\n",
      "Accuracy: 81.69\n",
      "Accuracy: 81.69\n",
      "Accuracy: 81.69\n",
      "Accuracy: 81.69\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.67\n",
      "Accuracy: 81.63\n",
      "Accuracy: 81.63\n",
      "Accuracy: 81.63\n",
      "Accuracy: 81.63\n",
      "Accuracy: 81.29\n",
      "Accuracy: 81.29\n",
      "Accuracy: 81.29\n",
      "Accuracy: 81.29\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "penalties  = ['l2']\n",
    "fit_intercepts = [False, True]\n",
    "Cs = [0.03, 0.02, 0.01, 0.005, 0.004, 0.003, 0.002, 0.001]\n",
    "solvers = ['newton-cg', 'sag', 'saga', 'lbfgs']\n",
    "\n",
    "for penalty in penalties:\n",
    "    for fit_intercept in fit_intercepts:    \n",
    "        for C in Cs:\n",
    "            for solver in solvers:\n",
    "                with mlflow.start_run():\n",
    "                    lr = LogisticRegression(penalty=penalty,\n",
    "                                        fit_intercept=fit_intercept,\n",
    "                                        C=C,\n",
    "                                        solver=solver)\n",
    "            \n",
    "                    lr.fit(train_x, train_y)\n",
    "                    accuracy = lr.score(test_x, test_y)\n",
    "\n",
    "                    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "                    print(\"Accuracy: %s\" % round((accuracy * 100),2))\n",
    "\n",
    "                    # Logging in mlflow to appears in UI\n",
    "                    mlflow.log_param(\"penalty\", penalty)\n",
    "                    mlflow.log_param(\"fit_intercept\", fit_intercept)\n",
    "                    mlflow.log_param(\"C\", C)\n",
    "\n",
    "                    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                    mlflow.sklearn.log_model(lr, \"model_logistic_regression\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
